"""
Enterprise Security Service for CloudMind - Phase 4
World-class security with compliance, monitoring, and threat detection
"""

import asyncio
import logging
import json
import hashlib
import secrets
import hmac
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import jwt
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import bcrypt
import ipaddress
import re

from app.core.config import settings

logger = logging.getLogger(__name__)


class SecurityLevel(Enum):
    """Security levels"""
    BASIC = "basic"
    STANDARD = "standard"
    ENTERPRISE = "enterprise"
    MILITARY = "military"


class ComplianceFramework(Enum):
    """Compliance frameworks"""
    SOC2 = "soc2"
    HIPAA = "hipaa"
    GDPR = "gdpr"
    PCI_DSS = "pci_dss"
    ISO_27001 = "iso_27001"
    NIST = "nist"
    FEDRAMP = "fedramp"


class ThreatLevel(Enum):
    """Threat levels"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class SecurityEvent:
    """Security event"""
    id: str
    event_type: str
    severity: ThreatLevel
    description: str
    source_ip: str
    user_id: Optional[str]
    timestamp: datetime
    metadata: Dict[str, Any]
    resolved: bool = False


@dataclass
class ComplianceReport:
    """Compliance report"""
    framework: ComplianceFramework
    status: str
    score: float
    findings: List[Dict[str, Any]]
    recommendations: List[str]
    last_audit: datetime
    next_audit: datetime


class EnterpriseSecurityService:
    """Enterprise-grade security service with world-class features"""
    
    def __init__(self):
        self.security_level = SecurityLevel.ENTERPRISE
        self.compliance_frameworks = []
        self.encryption_key = None
        self.rate_limit_cache = {}
        self.security_events = []
        self.threat_detection_rules = []
        self.audit_log = []
        
        # Initialize security components
        self._initialize_encryption()
        self._initialize_compliance_frameworks()
        self._initialize_threat_detection()
        self._initialize_audit_logging()
        
        logger.info("üõ°Ô∏è Enterprise Security Service initialized successfully!")
    
    def _initialize_encryption(self):
        """Initialize encryption components"""
        try:
            # Generate or load encryption key
            if hasattr(settings, 'ENCRYPTION_KEY') and settings.ENCRYPTION_KEY:
                self.encryption_key = Fernet(settings.ENCRYPTION_KEY.encode())
            else:
                # Generate new key for development
                key = Fernet.generate_key()
                self.encryption_key = Fernet(key)
                logger.warning("‚ö†Ô∏è Generated new encryption key for development")
            
            logger.info("‚úÖ Encryption initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Encryption initialization failed: {e}")
    
    def _initialize_compliance_frameworks(self):
        """Initialize compliance frameworks"""
        try:
            # Enable compliance frameworks based on settings
            if settings.ENABLE_SOC2_COMPLIANCE:
                self.compliance_frameworks.append(ComplianceFramework.SOC2)
            
            if settings.ENABLE_HIPAA_COMPLIANCE:
                self.compliance_frameworks.append(ComplianceFramework.HIPAA)
            
            if settings.ENABLE_GDPR_COMPLIANCE:
                self.compliance_frameworks.append(ComplianceFramework.GDPR)
            
            if settings.ENABLE_PCI_DSS_COMPLIANCE:
                self.compliance_frameworks.append(ComplianceFramework.PCI_DSS)
            
            if settings.ENABLE_ISO_27001_COMPLIANCE:
                self.compliance_frameworks.append(ComplianceFramework.ISO_27001)
            
            logger.info(f"‚úÖ Compliance frameworks initialized: {[f.value for f in self.compliance_frameworks]}")
            
        except Exception as e:
            logger.error(f"‚ùå Compliance frameworks initialization failed: {e}")
    
    def _initialize_threat_detection(self):
        """Initialize threat detection rules"""
        try:
            # Define threat detection rules
            self.threat_detection_rules = [
                {
                    "name": "brute_force_attack",
                    "pattern": r"failed_login.*5",
                    "threshold": 5,
                    "time_window": 300,  # 5 minutes
                    "severity": ThreatLevel.HIGH
                },
                {
                    "name": "sql_injection_attempt",
                    "pattern": r"(union|select|insert|delete|drop|create).*sql",
                    "threshold": 1,
                    "time_window": 60,
                    "severity": ThreatLevel.CRITICAL
                },
                {
                    "name": "xss_attempt",
                    "pattern": r"<script|javascript:|onload=|onerror=",
                    "threshold": 1,
                    "time_window": 60,
                    "severity": ThreatLevel.HIGH
                },
                {
                    "name": "suspicious_ip",
                    "pattern": r"ip_blacklist",
                    "threshold": 1,
                    "time_window": 3600,
                    "severity": ThreatLevel.MEDIUM
                },
                {
                    "name": "rate_limit_exceeded",
                    "pattern": r"rate_limit.*exceeded",
                    "threshold": 10,
                    "time_window": 60,
                    "severity": ThreatLevel.MEDIUM
                }
            ]
            
            logger.info(f"‚úÖ Threat detection rules initialized: {len(self.threat_detection_rules)} rules")
            
        except Exception as e:
            logger.error(f"‚ùå Threat detection initialization failed: {e}")
    
    def _initialize_audit_logging(self):
        """Initialize audit logging"""
        try:
            # Set up audit logging configuration
            self.audit_config = {
                "enabled": settings.ENABLE_AUDIT_LOGGING,
                "retention_days": 365,
                "encryption": True,
                "integrity_checking": True
            }
            
            logger.info("‚úÖ Audit logging initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Audit logging initialization failed: {e}")
    
    async def authenticate_user(self, username: str, password: str, ip_address: str) -> Dict[str, Any]:
        """Enterprise-grade user authentication with security checks"""
        try:
            # Log authentication attempt
            await self._log_security_event(
                "authentication_attempt",
                ThreatLevel.LOW,
                f"Login attempt for user: {username}",
                ip_address,
                None
            )
            
            # Check rate limiting
            if await self._is_rate_limited(ip_address, "auth"):
                await self._log_security_event(
                    "rate_limit_exceeded",
                    ThreatLevel.MEDIUM,
                    f"Rate limit exceeded for IP: {ip_address}",
                    ip_address,
                    None
                )
                raise Exception("Rate limit exceeded. Please try again later.")
            
            # Check for suspicious IP
            if await self._is_suspicious_ip(ip_address):
                await self._log_security_event(
                    "suspicious_ip",
                    ThreatLevel.MEDIUM,
                    f"Suspicious IP detected: {ip_address}",
                    ip_address,
                    None
                )
            
            # Perform authentication (placeholder - would integrate with actual auth system)
            auth_result = await self._perform_authentication(username, password)
            
            if auth_result["success"]:
                # Generate secure session token
                session_token = await self._generate_secure_session_token(username, ip_address)
                
                # Log successful authentication
                await self._log_security_event(
                    "authentication_success",
                    ThreatLevel.LOW,
                    f"Successful login for user: {username}",
                    ip_address,
                    username
                )
                
                return {
                    "success": True,
                    "session_token": session_token,
                    "user_id": auth_result["user_id"],
                    "security_level": self.security_level.value,
                    "mfa_required": auth_result.get("mfa_required", False)
                }
            else:
                # Log failed authentication
                await self._log_security_event(
                    "authentication_failure",
                    ThreatLevel.MEDIUM,
                    f"Failed login for user: {username}",
                    ip_address,
                    username
                )
                
                return {
                    "success": False,
                    "error": "Invalid credentials",
                    "remaining_attempts": auth_result.get("remaining_attempts", 0)
                }
                
        except Exception as e:
            logger.error(f"‚ùå Authentication failed: {e}")
            raise
    
    async def _perform_authentication(self, username: str, password: str) -> Dict[str, Any]:
        """Perform actual authentication"""
        try:
            # This would integrate with your actual authentication system
            # For now, return a placeholder result
            
            # Simulate authentication logic
            if username == "admin" and password == "secure_password":
                return {
                    "success": True,
                    "user_id": "user_123",
                    "mfa_required": True
                }
            else:
                return {
                    "success": False,
                    "remaining_attempts": 4
                }
                
        except Exception as e:
            logger.error(f"‚ùå Authentication logic failed: {e}")
            return {"success": False, "error": str(e)}
    
    async def _generate_secure_session_token(self, username: str, ip_address: str) -> str:
        """Generate secure session token with enterprise security"""
        try:
            # Create token payload
            payload = {
                "user": username,
                "ip": ip_address,
                "iat": datetime.utcnow(),
                "exp": datetime.utcnow() + timedelta(hours=1),  # 1 hour expiry
                "jti": secrets.token_urlsafe(32),  # Unique token ID
                "security_level": self.security_level.value
            }
            
            # Generate JWT token with strong secret
            secret = settings.SECRET_KEY if hasattr(settings, 'SECRET_KEY') else secrets.token_urlsafe(64)
            token = jwt.encode(payload, secret, algorithm="HS256")
            
            # Encrypt token for additional security
            encrypted_token = self.encryption_key.encrypt(token.encode())
            
            return encrypted_token.decode()
            
        except Exception as e:
            logger.error(f"‚ùå Session token generation failed: {e}")
            raise
    
    async def validate_session_token(self, token: str, ip_address: str) -> Dict[str, Any]:
        """Validate session token with security checks"""
        try:
            # Decrypt token
            decrypted_token = self.encryption_key.decrypt(token.encode())
            
            # Decode JWT
            secret = settings.SECRET_KEY if hasattr(settings, 'SECRET_KEY') else secrets.token_urlsafe(64)
            payload = jwt.decode(decrypted_token, secret, algorithms=["HS256"])
            
            # Check token expiry
            if datetime.utcnow() > payload["exp"]:
                raise Exception("Token expired")
            
            # Check IP address (prevent token reuse from different IPs)
            if payload["ip"] != ip_address:
                await self._log_security_event(
                    "token_ip_mismatch",
                    ThreatLevel.HIGH,
                    f"Token used from different IP. Original: {payload['ip']}, Current: {ip_address}",
                    ip_address,
                    payload["user"]
                )
                raise Exception("Token invalid for current IP")
            
            # Check if token is blacklisted
            if await self._is_token_blacklisted(payload["jti"]):
                raise Exception("Token blacklisted")
            
            return {
                "valid": True,
                "user": payload["user"],
                "security_level": payload["security_level"],
                "expires_at": payload["exp"]
            }
            
        except Exception as e:
            logger.error(f"‚ùå Token validation failed: {e}")
            return {"valid": False, "error": str(e)}
    
    async def _is_rate_limited(self, ip_address: str, action: str) -> bool:
        """Check if IP is rate limited"""
        try:
            current_time = datetime.now()
            key = f"{ip_address}:{action}"
            
            if key not in self.rate_limit_cache:
                self.rate_limit_cache[key] = []
            
            # Clean old entries
            self.rate_limit_cache[key] = [
                timestamp for timestamp in self.rate_limit_cache[key]
                if (current_time - timestamp).seconds < 60  # 1 minute window
            ]
            
            # Check rate limit
            max_requests = int(settings.RATE_LIMIT_REQUESTS) if hasattr(settings, 'RATE_LIMIT_REQUESTS') else 100
            if len(self.rate_limit_cache[key]) >= max_requests:
                return True
            
            # Add current request
            self.rate_limit_cache[key].append(current_time)
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Rate limiting check failed: {e}")
            return False
    
    async def _is_suspicious_ip(self, ip_address: str) -> bool:
        """Check if IP address is suspicious"""
        try:
            # Check if IP is in private range (suspicious for external access)
            ip = ipaddress.ip_address(ip_address)
            if ip.is_private:
                return True
            
            # Check against known malicious IP lists (placeholder)
            malicious_ips = [
                "192.168.1.100",  # Example malicious IP
                "10.0.0.50"       # Example malicious IP
            ]
            
            if ip_address in malicious_ips:
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Suspicious IP check failed: {e}")
            return False
    
    async def _is_token_blacklisted(self, token_id: str) -> bool:
        """Check if token is blacklisted"""
        try:
            # This would check against a blacklist database
            # For now, return False (no blacklisted tokens)
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Token blacklist check failed: {e}")
            return True  # Fail secure
    
    async def _log_security_event(self, event_type: str, severity: ThreatLevel, description: str, source_ip: str, user_id: Optional[str]):
        """Log security event with enterprise features"""
        try:
            event = SecurityEvent(
                id=secrets.token_urlsafe(16),
                event_type=event_type,
                severity=severity,
                description=description,
                source_ip=source_ip,
                user_id=user_id,
                timestamp=datetime.now(),
                metadata={
                    "security_level": self.security_level.value,
                    "compliance_frameworks": [f.value for f in self.compliance_frameworks]
                }
            )
            
            # Add to security events list
            self.security_events.append(event)
            
            # Check for threat patterns
            await self._check_threat_patterns(event)
            
            # Log to audit trail
            await self._add_to_audit_log(event)
            
            # Send alert for high/critical events
            if severity in [ThreatLevel.HIGH, ThreatLevel.CRITICAL]:
                await self._send_security_alert(event)
            
            logger.info(f"üõ°Ô∏è Security event logged: {event_type} - {severity.value}")
            
        except Exception as e:
            logger.error(f"‚ùå Security event logging failed: {e}")
    
    async def _check_threat_patterns(self, event: SecurityEvent):
        """Check for threat patterns and trigger alerts"""
        try:
            for rule in self.threat_detection_rules:
                if re.search(rule["pattern"], event.description.lower()):
                    # Pattern matched - check threshold
                    recent_events = [
                        e for e in self.security_events
                        if e.event_type == event.event_type
                        and (datetime.now() - e.timestamp).seconds < rule["time_window"]
                    ]
                    
                    if len(recent_events) >= rule["threshold"]:
                        # Threshold exceeded - create threat alert
                        threat_event = SecurityEvent(
                            id=secrets.token_urlsafe(16),
                            event_type=f"threat_detected_{rule['name']}",
                            severity=rule["severity"],
                            description=f"Threat pattern detected: {rule['name']}",
                            source_ip=event.source_ip,
                            user_id=event.user_id,
                            timestamp=datetime.now(),
                            metadata={
                                "rule": rule["name"],
                                "pattern": rule["pattern"],
                                "threshold": rule["threshold"],
                                "matched_events": len(recent_events)
                            }
                        )
                        
                        self.security_events.append(threat_event)
                        await self._send_security_alert(threat_event)
                        
        except Exception as e:
            logger.error(f"‚ùå Threat pattern check failed: {e}")
    
    async def _add_to_audit_log(self, event: SecurityEvent):
        """Add event to audit log with integrity checking"""
        try:
            audit_entry = {
                "timestamp": event.timestamp.isoformat(),
                "event_type": event.event_type,
                "severity": event.severity.value,
                "description": event.description,
                "source_ip": event.source_ip,
                "user_id": event.user_id,
                "metadata": event.metadata
            }
            
            # Add integrity hash
            entry_hash = hashlib.sha256(json.dumps(audit_entry, sort_keys=True).encode()).hexdigest()
            audit_entry["integrity_hash"] = entry_hash
            
            # Encrypt audit entry if enabled
            if self.audit_config["encryption"]:
                audit_entry = self.encryption_key.encrypt(json.dumps(audit_entry).encode()).decode()
            
            self.audit_log.append(audit_entry)
            
        except Exception as e:
            logger.error(f"‚ùå Audit log addition failed: {e}")
    
    async def _send_security_alert(self, event: SecurityEvent):
        """Send security alert for critical events"""
        try:
            alert_data = {
                "event_id": event.id,
                "event_type": event.event_type,
                "severity": event.severity.value,
                "description": event.description,
                "source_ip": event.source_ip,
                "timestamp": event.timestamp.isoformat(),
                "metadata": event.metadata
            }
            
            # This would integrate with your alerting system
            # For now, just log the alert
            logger.warning(f"üö® SECURITY ALERT: {event.severity.value.upper()} - {event.description}")
            
            # Could send email, Slack, SMS, etc.
            # await self._send_email_alert(alert_data)
            # await self._send_slack_alert(alert_data)
            
        except Exception as e:
            logger.error(f"‚ùå Security alert sending failed: {e}")
    
    async def generate_compliance_report(self, framework: ComplianceFramework) -> ComplianceReport:
        """Generate compliance report for specified framework"""
        try:
            # This would perform actual compliance checks
            # For now, return a sample report
            
            findings = []
            recommendations = []
            
            if framework == ComplianceFramework.SOC2:
                findings = [
                    {"control": "CC6.1", "status": "compliant", "description": "Logical access security software"},
                    {"control": "CC6.2", "status": "compliant", "description": "Access to system components"},
                    {"control": "CC6.3", "status": "compliant", "description": "Identification and authentication"}
                ]
                recommendations = [
                    "Implement additional access controls",
                    "Enhance monitoring capabilities",
                    "Regular security training for staff"
                ]
            
            elif framework == ComplianceFramework.HIPAA:
                findings = [
                    {"control": "164.312(a)(1)", "status": "compliant", "description": "Access control"},
                    {"control": "164.312(c)(1)", "status": "compliant", "description": "Integrity"},
                    {"control": "164.312(d)", "status": "compliant", "description": "Person or entity authentication"}
                ]
                recommendations = [
                    "Implement additional encryption",
                    "Enhance audit logging",
                    "Regular risk assessments"
                ]
            
            return ComplianceReport(
                framework=framework,
                status="compliant",
                score=95.0,
                findings=findings,
                recommendations=recommendations,
                last_audit=datetime.now(),
                next_audit=datetime.now() + timedelta(days=365)
            )
            
        except Exception as e:
            logger.error(f"‚ùå Compliance report generation failed: {e}")
            raise
    
    async def encrypt_sensitive_data(self, data: str) -> str:
        """Encrypt sensitive data with enterprise-grade encryption"""
        try:
            encrypted_data = self.encryption_key.encrypt(data.encode())
            return encrypted_data.decode()
            
        except Exception as e:
            logger.error(f"‚ùå Data encryption failed: {e}")
            raise
    
    async def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """Decrypt sensitive data"""
        try:
            decrypted_data = self.encryption_key.decrypt(encrypted_data.encode())
            return decrypted_data.decode()
            
        except Exception as e:
            logger.error(f"‚ùå Data decryption failed: {e}")
            raise
    
    async def validate_input_security(self, input_data: str, input_type: str) -> Dict[str, Any]:
        """Validate input for security vulnerabilities"""
        try:
            validation_result = {
                "valid": True,
                "warnings": [],
                "sanitized_data": input_data
            }
            
            # Check for SQL injection
            sql_patterns = [
                r"(\b(union|select|insert|delete|drop|create|alter|exec|execute)\b)",
                r"(\b(and|or)\b\s+\d+\s*=\s*\d+)",
                r"(\b(and|or)\b\s+['\"].*['\"])"
            ]
            
            for pattern in sql_patterns:
                if re.search(pattern, input_data, re.IGNORECASE):
                    validation_result["valid"] = False
                    validation_result["warnings"].append("Potential SQL injection detected")
            
            # Check for XSS
            xss_patterns = [
                r"<script[^>]*>.*?</script>",
                r"javascript:",
                r"on\w+\s*=",
                r"<iframe[^>]*>",
                r"<object[^>]*>"
            ]
            
            for pattern in xss_patterns:
                if re.search(pattern, input_data, re.IGNORECASE):
                    validation_result["valid"] = False
                    validation_result["warnings"].append("Potential XSS attack detected")
            
            # Check for command injection
            cmd_patterns = [
                r"[;&|`$()]",
                r"\b(cat|ls|pwd|whoami|id|uname)\b"
            ]
            
            for pattern in cmd_patterns:
                if re.search(pattern, input_data, re.IGNORECASE):
                    validation_result["warnings"].append("Potential command injection detected")
            
            # Sanitize data if needed
            if not validation_result["valid"]:
                # Basic sanitization
                sanitized = re.sub(r'[<>"\']', '', input_data)
                validation_result["sanitized_data"] = sanitized
            
            return validation_result
            
        except Exception as e:
            logger.error(f"‚ùå Input validation failed: {e}")
            return {"valid": False, "warnings": ["Validation error"], "sanitized_data": ""}
    
    def get_security_metrics(self) -> Dict[str, Any]:
        """Get security metrics and statistics"""
        try:
            current_time = datetime.now()
            
            # Calculate metrics
            total_events = len(self.security_events)
            recent_events = len([e for e in self.security_events if (current_time - e.timestamp).days < 1])
            
            threat_levels = {}
            for level in ThreatLevel:
                threat_levels[level.value] = len([e for e in self.security_events if e.severity == level])
            
            return {
                "security_level": self.security_level.value,
                "compliance_frameworks": [f.value for f in self.compliance_frameworks],
                "total_security_events": total_events,
                "events_last_24h": recent_events,
                "threat_distribution": threat_levels,
                "rate_limit_cache_size": len(self.rate_limit_cache),
                "audit_log_size": len(self.audit_log),
                "encryption_enabled": self.encryption_key is not None,
                "threat_detection_rules": len(self.threat_detection_rules)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Security metrics generation failed: {e}")
            return {}
